{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sethizzle4/AI-Ml/blob/main/bike_sharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrYFGFvgxa7h"
      },
      "outputs": [],
      "source": [
        "# The City College of New York, City University of New York\n",
        "# Written by Ricardo Valdez and Jian Wen Choong\n",
        "# August, 2020\n",
        "# Data for this example was taken from:\n",
        "# https://www.kaggle.com/hmavrodiev/london-bike-sharing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3torSYHxa7m",
        "scrolled": true,
        "outputId": "bc79d6e9-ba77-4b9c-a27a-2a2234ab3f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "********************************************************************\n",
            "****  WELCOME TO BIKE SHARING USING ARTIFICIAL NEURAL NETWORKS  ****\n",
            "********************************************************************\n",
            "\n",
            "OPTIONS:\n",
            "1 - Train a new ANN model\n",
            "2 - Load an existing model\n",
            "\n",
            "Select an option by entering a number: \n",
            "1\n",
            "\n",
            "********* NOW TRAINING ANN USING london_bike_sharing_data.csv *********\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1309246.1250\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1318541.7500\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1234947.0000\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1313873.3750\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1291972.0000 \n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1473127.6250 \n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1287311.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1272128.3750\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1438790.8750\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1220815.3750\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1177216.6250\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1334887.5000\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1299718.5000\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1260976.5000 \n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1215359.2500\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1255090.1250\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1607297.7500 \n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1303580.6250\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1220298.5000\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1276827.7500 \n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1347400.1250 \n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1436022.7500 \n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1276453.3750\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1264962.6250\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1264985.0000 \n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1374496.2500 \n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1473685.1250 \n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1404974.7500 \n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1279043.7500 \n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1207783.5000 \n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1471536.3750 \n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1213995.6250\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1326457.8750\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1332832.8750 \n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1368194.6250 \n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1241832.2500\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1417553.3750 \n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1319698.2500 \n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1249516.7500 \n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1278242.1250 \n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1344800.0000 \n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1268472.0000 \n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1180503.1250\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1365980.0000 \n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1257182.0000 \n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1329600.1250 \n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1279679.7500 \n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1268205.2500\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1292034.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1221142.8750\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1327845.2500\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1264041.1250\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1330877.3750\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1346117.5000 \n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1231219.8750\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1347795.0000 \n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1307064.1250\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1362859.5000 \n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1493073.0000 \n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1339834.1250 \n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1405636.0000 \n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1234715.7500\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1466077.6250 \n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1214951.8750\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1375712.1250 \n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1306405.5000\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1412302.0000 \n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1229043.5000 \n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1337282.7500 \n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1370534.3750 \n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1341560.2500\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1427532.1250 \n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1094363.6250\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1305247.8750 \n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1377458.0000 \n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1300838.5000 \n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1305878.8750 \n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1458479.3750 \n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1325422.2500 \n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1188264.3750\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1338870.6250 \n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1510114.1250 \n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1273427.1250 \n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1325246.5000 \n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1178064.1250 \n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1200389.2500 \n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1282993.3750 \n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1377634.2500 \n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1425892.8750 \n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1335221.7500 \n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1348754.7500 \n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1270868.3750 \n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1322066.8750 \n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1260177.2500\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1318650.7500 \n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1237062.2500\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1297269.0000 \n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1314342.5000 \n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1132194.8750\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1320311.3750\n",
            "\n",
            "\n",
            "********** ANN training complete **********\n",
            "\n",
            "\n",
            "\n",
            "******* WEIGHTS OF ANN *******\n",
            "\n",
            "Weights W0:\n",
            " [[-0.33202597  0.11254487  0.17611822 -0.6153454  -0.11690753  0.7305687\n",
            "  -0.4096533   0.6049999   0.16214173 -0.07194345]\n",
            " [-0.24198698  0.7356912   0.43783572 -0.14405032  0.4027451  -0.08561406\n",
            "   0.31210202  0.55183774  0.5411049   0.26550147]\n",
            " [ 0.03641457  0.67094886  0.00900211 -0.5195366   0.22465687  0.03196738\n",
            "  -0.71789813 -0.25359827  0.50716937  0.8722282 ]\n",
            " [-0.86489314  0.40708932  0.11427225 -0.78521377 -0.01119448 -0.1216978\n",
            "   0.4095232  -0.5817801   0.5532885   0.645545  ]\n",
            " [-0.22324929 -0.1777802   0.2190773  -0.82346076  0.06544711  0.5253361\n",
            "  -0.7028888   0.5810541   0.4007859   0.6594027 ]]\n",
            "Bias b0:\n",
            " [-0.32769832  0.21787773  0.42858252 -0.1911055   0.3648118   0.177553\n",
            " -0.11660805  0.03480159  0.26663697  0.32313973]\n",
            "Weights W1:\n",
            " [[ 2.5402769e-01 -5.9766942e-01 -1.7694531e-01 -3.4806371e-01\n",
            "   1.1986048e-03  4.2856595e-01 -5.5424845e-01]\n",
            " [ 7.4921739e-01  3.0067533e-02  1.9292003e-03  8.7338406e-01\n",
            "  -1.6139734e-01 -8.7752268e-02  1.1336753e+00]\n",
            " [ 7.7710080e-01  2.3551375e-01  8.8086897e-01  1.3103697e+00\n",
            "   1.1008129e+00  2.4394734e-01  8.9939290e-01]\n",
            " [-3.0735713e-01 -2.0000683e-01  4.4112660e-02  1.1726266e-01\n",
            "   4.8081985e-01 -3.9633278e-02  2.7135143e-01]\n",
            " [ 3.2497305e-01  9.6793331e-02  2.1250400e-01  3.5944250e-01\n",
            "   9.6753961e-01 -2.9979093e-02  4.7952569e-01]\n",
            " [ 8.9500916e-01  1.4798094e-01  4.6469167e-01  7.9454762e-01\n",
            "   1.9142178e-01 -4.2200595e-01  9.3497038e-01]\n",
            " [-2.0516230e-01 -1.3829790e-01 -2.8012946e-01  6.7108917e-01\n",
            "   2.2577725e-01  4.8324683e-01  3.5602406e-02]\n",
            " [ 1.8995325e-01 -1.2338694e-01 -1.9033905e-02  4.4543812e-01\n",
            "   6.8554032e-01 -2.4220917e-01  7.9413742e-01]\n",
            " [ 3.7362489e-01  6.6258967e-02  4.5419219e-01  9.4239458e-02\n",
            "   7.7129108e-01  3.7673190e-01  2.8812689e-01]\n",
            " [ 4.6289006e-01  8.5960555e-01  8.8056594e-01  6.9661736e-01\n",
            "   4.8137620e-01  4.6979910e-01  5.2886039e-02]]\n",
            "Bias b1:\n",
            " [0.3235308  0.35692206 0.4853888  0.38600776 0.3077537  0.11308255\n",
            " 0.6284028 ]\n",
            "Weights W2:\n",
            " [[-1.1395289   0.24253051  0.7708278  -0.5692343  -1.1611276 ]\n",
            " [ 0.00391009  1.3342794   0.36042172  0.33246464 -0.72205114]\n",
            " [-1.3412714  -0.00708938  1.729889   -0.669035   -0.9721404 ]\n",
            " [-0.5663969   0.84460163  1.1729431  -1.3162699  -0.44064307]\n",
            " [-0.9438994   0.5113601   0.4467859  -0.9331511  -1.108302  ]\n",
            " [ 0.5404172   0.95158315 -0.01305283 -0.46789137  0.26940432]\n",
            " [-1.1871567   0.7011384   1.0937961  -1.1634524  -0.18790954]]\n",
            "Bias b2:\n",
            " [-0.3891441   0.24117571  0.92769945 -0.5115631  -0.44356605]\n",
            "Weights W3:\n",
            " [[-0.23824543]\n",
            " [ 1.1384283 ]\n",
            " [ 2.6587331 ]\n",
            " [-0.44631913]\n",
            " [ 0.00926284]]\n",
            "Bias b3:\n",
            " [2.0654836]\n",
            "\n",
            "\n",
            "Enter temperature in Celcius: \n",
            "9\n",
            "Enter hour of the day (military): (0-23) \n",
            "17\n",
            "Is it the weekend? (y/n): \n",
            "n\n",
            "Enter wind speed: (km/h) \n",
            "22\n",
            "Enter weather code: (1 = clear, 2 = few clouds, 3 = broken clouds, 4 = cloudy, 7 = rain, 10 = thunderstorm, 26 = snow, 94 = freezing fog) \n",
            "2\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
            "\n",
            "*****************************************\n",
            "ANN Predicted number of shared bikes: 6\n",
            "*****************************************\n",
            "\n",
            "\n",
            "Would you like to continue? (y/n): \n",
            "y\n",
            "\n",
            "\n",
            "Enter temperature in Celcius: \n",
            "0\n",
            "Enter hour of the day (military): (0-23) \n",
            "0\n",
            "Is it the weekend? (y/n): \n",
            "0\n",
            "Enter wind speed: (km/h) \n",
            "40\n",
            "Enter weather code: (1 = clear, 2 = few clouds, 3 = broken clouds, 4 = cloudy, 7 = rain, 10 = thunderstorm, 26 = snow, 94 = freezing fog) \n",
            "10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\n",
            "*****************************************\n",
            "ANN Predicted number of shared bikes: 6\n",
            "*****************************************\n",
            "\n",
            "\n",
            "Would you like to continue? (y/n): \n",
            "n\n",
            "\n",
            "\n",
            "Would you like to save the ANN model? (y/n): \n",
            "y\n",
            "\n",
            "\n",
            "Enter a name for the save file: \n",
            "2762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "***** ANN MODEL SUCCESSFULLY SAVED AS 2762.h5 *****\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tensorflow import keras\n",
        "\n",
        "# import print_weights as pw\n",
        "# call: pw.print_weights()\n",
        "\n",
        "def print_weights(weights):\n",
        "    # weights = model.get_weights();\n",
        "    print('\\n******* WEIGHTS OF ANN *******\\n')\n",
        "    for i in range(int(len(weights)/2)):\n",
        "        print('Weights W%d:\\n' %(i), weights[i*2])\n",
        "        print('Bias b%d:\\n' %(i), weights[(i*2)+1])\n",
        "#END print_weights()\n",
        "\n",
        "#% ANN TRAINING\n",
        "print('\\n')\n",
        "print('********************************************************************')\n",
        "print('****  WELCOME TO BIKE SHARING USING ARTIFICIAL NEURAL NETWORKS  ****')\n",
        "print('********************************************************************')\n",
        "\n",
        "# prompt user to train or load an ANN model\n",
        "option_list = ['1','2']\n",
        "option = ''\n",
        "while option not in option_list:\n",
        "    print('\\nOPTIONS:')\n",
        "    print('1 - Train a new ANN model')\n",
        "    print('2 - Load an existing model')\n",
        "\n",
        "    option = input('\\nSelect an option by entering a number: \\n')\n",
        "    if option not in option_list:\n",
        "        message = 'Invalid input: Input must be one of the following - '\n",
        "        print(message, option_list)\n",
        "        time.sleep(2)\n",
        "\n",
        "if option == '1':\n",
        "    ## OPTION 1: TRAIN A NEW ANN MODEL\n",
        "    train_data_file = 'london_bike_sharing_data.csv'\n",
        "\n",
        "    print('\\n********* NOW TRAINING ANN USING', train_data_file,'*********')\n",
        "    time.sleep(3)\n",
        "\n",
        "    ## load the training data\n",
        "    df = pd.read_csv(train_data_file)\n",
        "\n",
        "    ## the training data contains 7 columns:\n",
        "    ##\n",
        "    ##      timestamp - the date and time the sample was recorded\n",
        "    ##      new_bikes_shared - number of new bikes shared over the last hour\n",
        "    ##      is_weekend - boolean that is 1 (true) if the day is a weekend\n",
        "    ##      temp_c - the temperature in Celcius\n",
        "    ##      wind_speed - wind speed in km/h\n",
        "    ##      weather_code - category of weather: 1 = clear\n",
        "    ##                                          2 = scattered clouds\n",
        "    ##                                          3 = broken clouds\n",
        "    ##                                          4 = cloudy\n",
        "    ##                                          7 = rain\n",
        "    ##                                         10 = thunderstorm\n",
        "    ##                                         26 = snow\n",
        "    ##                                         94 = freezing fog\n",
        "\n",
        "    ## the timestamp column of df are stored as strings. We want to\n",
        "    ## convert each timestamp string into a datetime objects using the\n",
        "    ## function datetime.strptime(). The first input of datetime.strptime()\n",
        "    ## is the string you want to convert, and the second input is the\n",
        "    ## format of the string, where\n",
        "    ## %m = month, %d = day, %Y = year, %H = hour, %M = minute.\n",
        "    ##\n",
        "    ## create lambda function to perform conversion and return the hour.\n",
        "    get_hour = lambda timestamp: datetime.strptime(timestamp,\n",
        "                                                   '%m/%d/%Y %H:%M').hour\n",
        "    ## apply the lambda function to every timestamp in column df['timestamp']\n",
        "    df['time_hour'] = df['timestamp'].apply(get_hour)\n",
        "\n",
        "    ## define input matrix X (get rid of columns called timestamp and\n",
        "    ## new_bikes_shared)\n",
        "    X = np.array(df.drop(['timestamp','new_bikes_shared'], axis=1))\n",
        "    ## define expected output matrix Y\n",
        "    Y = np.array(df['new_bikes_shared'])\n",
        "\n",
        "    ## create a model for the ANN\n",
        "    model = keras.Sequential()\n",
        "    ## add a hidden layer that accepts 5 input features (time_hour, temp_c\n",
        "    ## wind_speed, weather_code, is_weekend)\n",
        "    ## the hidden layer has 5 neurons.\n",
        "    ## Dense means every neuron in the layer connects to every neuron in the\n",
        "    ## previous layer.\n",
        "    model.add(keras.layers.Dense(10, activation='sigmoid', input_shape=(5,)))\n",
        "    ## add another hidden layer with 6 neurons to the ANN\n",
        "    model.add(keras.layers.Dense(7, activation='sigmoid'))\n",
        "    ## add another hidden layer with 6 neurons to the ANN\n",
        "    model.add(keras.layers.Dense(5, activation='sigmoid'))\n",
        "    ## add an output layer with a single output (new_bikes_shared)\n",
        "    model.add(keras.layers.Dense(1, activation='linear'))\n",
        "\n",
        "    ## set the optimization algorithm used for minimizing loss function\n",
        "    ## use gradient descent (adam) to minimize error (loss)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    ## train the ANN model using 2000 iterations\n",
        "    model.fit(X, Y, epochs=100)\n",
        "\n",
        "    print('\\n\\n********** ANN training complete **********\\n\\n')\n",
        "elif option == '2':\n",
        "    ## OPTION 2: LOAD ANN MODEL FROM FILE\n",
        "\n",
        "    message = 'Enter the file name of the ANN Model you want to load: \\n'\n",
        "    load_file = input(message)\n",
        "    #load_file = input('It must be a .h5 file')\n",
        "\n",
        "    ## if file name does not end with '.h5', add '.h5' to the file name\n",
        "    if load_file[-3:] != '.h5':\n",
        "        load_file += '.h5'\n",
        "    ## load the ANN model from load_file\n",
        "    model = keras.models.load_model(load_file)\n",
        "\n",
        "    print('\\n\\n****** SUCCESSFULLY LOADED ANN MODEL FROM', load_file,'******')\n",
        "else:\n",
        "    print('ERROR: INVALID OPTION SELECTED')\n",
        "    ## raise an exception to terminate the program\n",
        "    raise ValueError()\n",
        "\n",
        "weights = model.get_weights();\n",
        "print_weights(weights)\n",
        "\n",
        "#% BIKE SHARING PREDICTION USING ANN\n",
        "# input('\\n\\n********** Press ENTER to start using the ANN **********\\n\\n')\n",
        "finished = False\n",
        "while not finished:\n",
        "    ## prompt user for inputs\n",
        "    temp_c = float(input('\\n\\nEnter temperature in Celcius: \\n'))\n",
        "    hour = float(input('Enter hour of the day (military): (0-23) \\n'))\n",
        "    is_weekend = input('Is it the weekend? (y/n): \\n')\n",
        "    if is_weekend == 'y':\n",
        "        is_weekend = 1\n",
        "    else:\n",
        "        is_weekend = 0\n",
        "    wind_speed = float(input('Enter wind speed: (km/h) \\n'))\n",
        "    weather_code = int(input('Enter weather code: (1 = clear, 2 = few clouds, '\n",
        "                   + '3 = broken clouds, 4 = cloudy, 7 = rain, '\n",
        "                   + '10 = thunderstorm, 26 = snow, 94 = freezing fog) \\n'))\n",
        "\n",
        "    user_input=np.array([[is_weekend, temp_c, wind_speed, weather_code,hour]])\n",
        "    prediction = model.predict(user_input)\n",
        "\n",
        "    ## restrict prediction to non-negative values\n",
        "    if prediction < 0:\n",
        "        prediction = 0.1\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    ## display prediction\n",
        "    print('\\n*****************************************')\n",
        "    print(f'ANN Predicted number of shared bikes: {prediction[0][0]:.0f}', )\n",
        "    print('*****************************************')\n",
        "    ## ask user if they would like to continue\n",
        "    choice = ''\n",
        "    while choice not in ['y','n']:\n",
        "        choice = input('\\n\\nWould you like to continue? (y/n): \\n')\n",
        "        if choice == 'y':\n",
        "            pass\n",
        "        elif choice == 'n':\n",
        "            finished = True\n",
        "        else:\n",
        "            print(\"Invalid input: Input must be 'y' or 'n'\")\n",
        "    #END WHILE\n",
        "#END WHILE\n",
        "\n",
        "## ask user if they would like to save the ANN model\n",
        "choice = ''\n",
        "while choice not in ['y','n']:\n",
        "    choice = input('\\n\\nWould you like to save the ANN model? (y/n): \\n')\n",
        "    if choice == 'y':\n",
        "        save_name = input('\\n\\nEnter a name for the save file: \\n')\n",
        "        ## if file name does not end with '.h5', add '.h5' to the file name\n",
        "        if save_name[-3:] != '.h5':\n",
        "            save_name += '.h5'\n",
        "        model.save(save_name)\n",
        "        print('\\n\\n')\n",
        "        print('***** ANN MODEL SUCCESSFULLY SAVED AS '+save_name+' *****')\n",
        "    elif choice == 'n':\n",
        "        pass\n",
        "    else:\n",
        "        print(\"Invalid input: Input must be 'y' or 'n'\")\n",
        "#END WHILE\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}